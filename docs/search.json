[
  {
    "objectID": "content/post/index.html",
    "href": "content/post/index.html",
    "title": "Blog Posts",
    "section": "",
    "text": "3D tracked!\n\n\n\n\n\n\n\n\nJan 19, 2021\n\n\nKlinkenberg\n\n\n\n\n\n\n\n\n\n\n\n\nLive Online Lecturing\n\n\n\n\n\n\n\n\nJan 10, 2021\n\n\nKlinkenberg\n\n\n\n\n\n\n\n\n\n\n\n\nMy Online Lecture Setup\n\n\n\n\n\n\n\n\nAug 16, 2020\n\n\nKlinkenberg\n\n\n\n\n\n\n\n\n\n\n\n\nBack to the Mac\n\n\n\n\n\n\n\n\nJul 24, 2020\n\n\nKlinkenberg\n\n\n\n\n\n\n\n\n\n\n\n\nPresentation Overlay\n\n\n\n\n\n\n\n\nApr 20, 2020\n\n\nKlinkenberg\n\n\n\n\n\n\n\n\n\n\n\n\nTiming is everything\n\n\n\n\n\n\n\n\nMar 11, 2020\n\n\nKlinkenberg\n\n\n\n\n\n\n\n\n\n\n\n\nI switched to windows!\n\n\n\n\n\n\n\n\nDec 28, 2019\n\n\nKlinkenberg\n\n\n\n\n\n\n\n\n\n\n\n\nNot 3D tracking yet\n\n\n\n\n\n\n\n\nDec 6, 2019\n\n\nKlinkenberg\n\n\n\n\n\n\n\n\n\n\n\n\n3D tracked knowledge video\n\n\n\n\n\n\n\n\nMar 20, 2019\n\n\nKlinkenberg\n\n\n\n\n\n\n\n\n\n\n\n\nVR is so last year\n\n\n\n\n\n\n\n\nMar 27, 2017\n\n\nKlinkenberg\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sharon Klinkenberg",
    "section": "",
    "text": "Dr Klinkenberg is a senior lecturer at the department of Communication Science. His teaching is mainly focused on statistics and research methods. Sharon is an educational innovator at the forefront of educational technology. As a winner of the national SURF education award, he specialized in digital assessment, and integrates formative and summative assessment in order to personalize large scale education. His research is focused on the validity and reliability of adaptive assessment methods and the effectiveness of blended learning interventions.\n\n\n\n\n\nDigital Assessment\nAdaptive Testing\nPsychometrics\nHigher Education\nEducational Technology\n\n\n\nEducational Leadership\nData Science\nLearning Analytics\nBlended Learning\nStatistics Education"
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Sharon Klinkenberg",
    "section": "",
    "text": "Dr Klinkenberg is a senior lecturer at the department of Communication Science. His teaching is mainly focused on statistics and research methods. Sharon is an educational innovator at the forefront of educational technology. As a winner of the national SURF education award, he specialized in digital assessment, and integrates formative and summative assessment in order to personalize large scale education. His research is focused on the validity and reliability of adaptive assessment methods and the effectiveness of blended learning interventions.\n\n\n\n\n\nDigital Assessment\nAdaptive Testing\nPsychometrics\nHigher Education\nEducational Technology\n\n\n\nEducational Leadership\nData Science\nLearning Analytics\nBlended Learning\nStatistics Education"
  },
  {
    "objectID": "index.html#research",
    "href": "index.html#research",
    "title": "Sharon Klinkenberg",
    "section": "Research",
    "text": "Research\n\nHighlighted Publications\nFull Publication List\nContent here"
  },
  {
    "objectID": "index.html#blog-posts",
    "href": "index.html#blog-posts",
    "title": "Sharon Klinkenberg",
    "section": "Blog posts",
    "text": "Blog posts\nAll blogs"
  },
  {
    "objectID": "content/post/switched/index.html",
    "href": "content/post/switched/index.html",
    "title": "I switched to windows!",
    "section": "",
    "text": "#OMG it really happened. I switched to windows. After some twenty years of personal Mac use, I decided to switch. Now I’m not a complete noob to windows. I had my fair share of windows 98 trouble shooting back in the day. You know, the days where buying a new computer really meant getting a beige box with a DOS floppy, and finding a windows cd and drivers and solving al the problems associated with owning a computer.\nBut the Mac was a big relief. It just worked. And, in a time where I needed to get actual work done, and I could afford a Mac, it was a very welcome relief. I managed for years to alleviate the price tag by selling after about two years, and getting a very reasonable return. So I went from a 12” MacBook to a 15” and then the black 13”, after which I stayed with the second generation MacBook air for two consecutive units, and eventually landing back at 12” with the 2015 MacBook.\nAnd there it started to lag. As I started to get restless and wanting to update, there was no update available. So I waited, and waited, but a significant update fell short. As I wanted to stay with the small form factor, the 2019 discontinuation of the 12” model was a major disappointment. So, I stuck to my 12” until it started to show problems with charging, battery life and random quirks.\nA new Machine was inevitable but witch one? As the departure from the 12” would land me in a category of Macs that was plagued by keyboard issues and were not on par with today’s processing specs, the decision to switch started to loom. There was a sparkle of hope with the introduction of the 16” MacBook pro, but the keyboard and spec update stayed limited to the largest Machine of the bunch.\n\n\n\n\n\n\nFigure 1: XPS 13\n\n\n\nSo, here I am, typing this blog on a DELL XPS 13” only slightly larger than my 12” MacBook, but with an intel 10th gen CPU, 16 gigs of RAM and a 512 SSD. Throwing on a 4K touch screen with a 10% discount, costed a fraction of the price of a Mac. Though windows 10 is the real price to pay.\nAs being formally trained in the adobe suite, and wanting the full-fledged system integration of outlook exchange for work, going with a Linux distro only was not an option. Though I do plan on going for a dual boot at one point, for now I’ll stick to windows 10. The first week has been pretty painless."
  },
  {
    "objectID": "content/post/2020-07-24-back-to-the-mac.en/index.html",
    "href": "content/post/2020-07-24-back-to-the-mac.en/index.html",
    "title": "Back to the Mac",
    "section": "",
    "text": "Remember that time I switched to windows? Well, after less than half a year, I already caved. Though I really tried to make this relationship work, in the end, there was just no love. Within a month of purchasing the DELL XPS 13, I already had significant regret. Not for Mac craving but because a new XPS was announced. An even slicker smaller better one than the one I just got. So, initially, it was not windows that made me restless. I even invested heavily in learning the superuser tricks. Installing linux subsystem for windows, getting to know a bunch of shortcuts, and diving deep into system thingies to customize the heck out of the XPS. Setting up incremental backups and system restore points, the whole shebang.\nAll the while, having that beautiful 4K touch screen to stare at. But wait, that screen is sucking the battery dry in no time. I ended up with a DELL powerbank because the ones I owned could not output 90 Watts.\nAnd then came the updates. The OCD in me wants to have an up to date system. So, I installed the first update, and the second, and they kept coming. Not just the windows updates, but also an insane amount of DELL command center updates. It just would not stop.\n\n\n\n\n\n\nFigure 1: MacBook Pro\n\n\n\nThat’s when I started to play around with Linux. Trying out different distros, but I always ran into one or the other problem. I was searching for solutions to problems I didn’t have on the Mac.\nAnd then, out of nowhere, came the salvation. Apple updated its MacBook Pro lineup. Bringing the 13-inch model back on spec with no keyboard issues anymore. So here I am, back in my walled garden, writing this blog on a Mac again."
  },
  {
    "objectID": "content/post/2020-08-16-lecture-setup/index.html",
    "href": "content/post/2020-08-16-lecture-setup/index.html",
    "title": "My Online Lecture Setup",
    "section": "",
    "text": "Strap in there, because this is going to be a deep dive. In a previous blog post, I already described how you could use open broadcast software (OBS) to overly a logo or presentation on your webcam feed, and switch between scenes while presenting. Based on that experience, I recently gave a two-hour online workshop taking this to the next level. The video below shows live interaction with the students. In this post, I will elaborate on how to connect all the applications and the hardware I use.\nAs I recently switched back to the mac, this post focusses on the setup for the mac only. Though it also works on windows. Sometimes even easier."
  },
  {
    "objectID": "content/post/2020-08-16-lecture-setup/index.html#connecting-obs-to-zoom",
    "href": "content/post/2020-08-16-lecture-setup/index.html#connecting-obs-to-zoom",
    "title": "My Online Lecture Setup",
    "section": "Connecting OBS to zoom",
    "text": "Connecting OBS to zoom\nUsing OBS as the central hub for all video input means we have to get that video feed into zoom. For windows, this is easy with the OBS webcam plugin. Though on the MAC, we have to use the Network Device Interface (NDI) plugin to send out a video and convert that to a virtual camera, using the NDI Virtual input application, which is available in the NDITools package at NDI.tv.\n\n\n\nCamera Setup\n\n\nWhile zoom initially supported virtual camera input, the current version 5.0.4 seems to break that support. Though by unsigning the zoom application, this problem can be resolved quickly. Just paste the following command in the terminal.\ncodesign --remove-signature /Applications/zoom.us.app\nNow, we are finally ready to stream video from OBS to zoom, and at the same time, we can record or stream the OBS output in HD, which lands us at the next problem. The only audio recorded is your voice and not the questions or conversations with your students.\nFor OBS to pick up the sound from zoom, the audio needs to be redirected. For this purpose, the best application on the mac is Loopback. However, this will set you back $120. I tried a bunch of free alternatives, but none seemed to work consistently.\nWhile this allowed me to record all the necessary audio and I could tell my students their faces would not end up online, the recordings do feel a bit eery, with student voices coming out of nowhere. To fix this problem, I added a spectralizer in OBS to visualize the audio from my students.\nIn my previous post on using OBS, I described using a second monitor to use as input for zoom. I recently realized this is not even needed. Because you can screen share in zoom using the same virtual camera input. Screen sharing in zoom forces the presenter mode on the students. So, you, as a teacher, are assured they are not just staring at each other."
  },
  {
    "objectID": "content/post/2020-08-16-lecture-setup/index.html#hardware",
    "href": "content/post/2020-08-16-lecture-setup/index.html#hardware",
    "title": "My Online Lecture Setup",
    "section": "Hardware",
    "text": "Hardware\nAs I am an award-winning amateur photographer :-) I have some camera gear lying around.\nSo, instead of using my laptop webcam, I connect my canon M50 camera through USB, added a continuous power source, and attached my 24mm F2 canon EF lens for a nice wide-angle. For audio, I recently switched to the RodeVideoMic NTG. Attached to the cold shoe of my camera, with a magic arm, it makes for a pretty compact recording setup. Though, the icing on the cake is the 3D printed camera mounted teleprompter, which I use with my iPhone running an extra zoom session. This way, it is easier to look straight into the camera at your students asking questions.\n\n\n\nUSB-C Hub\n\n\nWith only one USB-c hub connected to my mac, the USB from the M50 and Mic go straight into the MacBook pro. The USB-c hub also supports a network cable, which is a must to ensure an uninterrupted connection."
  },
  {
    "objectID": "content/post/2020-08-16-lecture-setup/index.html#tying-it-all-together",
    "href": "content/post/2020-08-16-lecture-setup/index.html#tying-it-all-together",
    "title": "My Online Lecture Setup",
    "section": "Tying it all together",
    "text": "Tying it all together\nSo, to run an online lecture, I fire up zoom on the computer and iPhone using the same account. iPhone in the teleprompter with all notifications and audio video turned off. I set the “starting in 5 minutes scene”, turn on screen sharing from 2nd camera (advanced tab) and hit record in OBS."
  },
  {
    "objectID": "content/post/2021-01-10-online-lecture/index.html",
    "href": "content/post/2021-01-10-online-lecture/index.html",
    "title": "Live Online Lecturing",
    "section": "",
    "text": "I have been teaching a large scale course amidst the pandemic. In this post, I want to share my experiences with live lecturing online.\nAs the course has been around for quite some time, we had the lecture recordings of previous years at our disposal. Though simply providing these recordings would have been an easy solution, it did not feel right to throw this over the fence and call it a day. To me, It felt like a signal to students that they could just figure it all out on their own. So the plan arose to provide live lectures. Spending way too many hours in zoom from March to June gave us the confidence to pull this off.\nAs mentioned in my previous blog, I used OBS as my central hub. Though the whole process has become much more straightforward with the new OBS virtual webcam feature. Just hit the start virtual webcam button, and you can use it in any video conferencing tool.\n\n\n\nDesk\n\n\nAs can be seen from the picture above, I teach from my kids’ bedroom, armed with a couple of NERF’s. I use apple’s Sidecar to use my iPad as a second monitor, clamped to a shelf with a JOBI tablet grip. Placed at eye level to the right of my camera, it matches the scene when I look at the screen.\n\n\n\nScreen grab\n\n\nMy camera has a cheap plastic teleprompter mounted. With my iPhone logged into zoom. This lets me see my presentation when I speak, see my students when they ask questions, and Look straight into the camera.\nFor audio, I use the amazingly versatile RØDE VideoMic NTG. Furthermore, the Stream Deck makes tactile scene switching a breeze. So, without looking away from the camera, I can easily change the scene.\nSpeaking of scenes, I essentially have two. One is a shoulder level shot, and the second is a side by side shot with about two-third desktop and one-third camera, as can be seen above. Additionally, I have a “starting in 5 minutes” and a “Right Back” scene. During the break, I actually step out and get a cup of coffee.\nLooking at the center monitor, you can see my desktop layout. I have OBS running at the right side. On the bottom left, the main zoom session, showing the chat and participants window. With so many students in a session, I sometimes have to mute all. The top left shows the YouTube Livestream panel. Yes, I stream the entire session for students who cannot attend the zoom session. Students that are constrained by timezones can view the lecture afterwards. Though some only watch the YouTube lecture at double speed.\nAs my internet service provider had a few outages, the web lecture recordings from the previous year served us well as a backup. Being logged in through my iPhone also proved to be very useful. Because I was still connected to students, I could tell them what was going on. And in one case, even continued my lecture on my phone.\nAs for the most important question, did our students actually enjoy this type of online lecture. Well, see for yourself in the video below.\n\n\nYou can find all my lectures in the following playlist on our YouTube Channel. Looking at the time indication, you can see that my classes are about two hours long. Though I recently came across some articles stating that this is way too long to retain concentration, I think we should not underestimate students. Apart from these lectures, our students also attend two-hour tutorial sessions and had weekly assignments. With the help of our outstanding tutors, I think we managed to pull off a pretty amazing online course."
  },
  {
    "objectID": "content/post/spotlight/index.html",
    "href": "content/post/spotlight/index.html",
    "title": "VR is so last year",
    "section": "",
    "text": "So, we’re done with VR for lecture recordings. Why? We just can’t see the presentation, let alone the laser pointer. VR is out. Enter the next generation of presenter tools: The Logi(tech) Spotlight. The spotlight presenter promises to boost your confidence. But let’s ignore that nonsense.\n\n\nThe Spotlight does deliver the main goal we had of merging the campus lectures and the online weblectures. The remote is able to project a digital spotlight on the screen which of course can be captured by the weblecture registration software that we have here on campus. With this technology students watching the weblectures can finally see what the lecturer is focusing on. Bang! Problem solved, almost. We do need to enable full video recordings instead of key frame capture. Have a look at the video below to see the spotlight in action. I also squeezed in some weblecture recordings so you can judge for yourself if the quality is good enough to replace VR.\n\n\nNow how does it work? It’s a gyroscope. The spotlight appears at the location of the mouse on your computer screen. Any movement of the remote translates to movement of the spotlight on screen. No matter where you point the remote, press the spotlight button and it works. Now that looks quite stupid if you’re pointing the wrong way, but the concept is genius. Point at a giant beamer screen and it just magically works. Why isn’t there an app for that?\nIf you are looking to blend campus lectures and online lectures, this is the tool for you. Oh, and one more thing. Did I mention that you don’t have to turn it on or off? That might sound trivial but I occasionally find myself out of batteries because I forgot to turn off my laser pointer. So now I don’t have to carry an extra battery pack around anymore."
  },
  {
    "objectID": "content/post/presentation_overlay/index.html",
    "href": "content/post/presentation_overlay/index.html",
    "title": "Presentation Overlay",
    "section": "",
    "text": "So, the webinar on distance assessment was received quite well. Apart from the 200 attendees and now almost a hundred views on YouTube, I also received many questions on how I created the presentation overlay as can be seen in the video below."
  },
  {
    "objectID": "content/post/presentation_overlay/index.html#all-about-the-layers",
    "href": "content/post/presentation_overlay/index.html#all-about-the-layers",
    "title": "Presentation Overlay",
    "section": "All about the layers",
    "text": "All about the layers\nTo create this effect, I stacked some video layers and applied some chroma-keying to make it all look smooth. For this, I used the opensource open broadcast software called OBS studio. The three essential layers needed are, of course, the webcam middle layer, a white image background layer, and the presentation layer, which is a PowerPoint with a chroma-key (green) background (Download Template).\n\nIn OBS you need to set the webcam layer’s opacity to 40% by applying a a color key filter, and you will get a more transparent image. To add the Powerpoint overlay, set Powerpoint to windowed mode and window capture this window in OBS. Watch this last video entirely for all the sources options available in OBS.\nIn the final step, you just need to select a second monitor as output in OBS and use this second monitor as input for your conferencing software like zoom, meets, or teams. Well, here you go.\nSo, am I satisfied? Nah, the text overlaying the eyes is just too distracting to me. I already experimented with using a half-width PowerPoint presentation, so you only use half of the screen. I’ll come back to that in the next post."
  },
  {
    "objectID": "content/post/GR_2019_blog_1/index.html",
    "href": "content/post/GR_2019_blog_1/index.html",
    "title": "3D tracked knowledge video",
    "section": "",
    "text": "It’s that time of the year again. The grass is turning green and so, it’s time for a new grassroots project. This time I’m going to dive into the world of 3D tracking in Adobe After Effects to create next level knowledge videos.\nI was inspired by the awesome Peter McKinnon and his short tutorial on how to merge 3D graphics and video footage. I thought, how cool would it be to explain some statistical concepts and have it play out right in front of me on the table. Looking at what AE Tutorials created, I could totally see this happening.\n\n\n\n\n\n\nSo, the grassroots project got approved and we’re going to do this. The goal is of course to create a few clips, but also to see how viable it is within the confounds of my own desktop computer and the Adobe CC suite. To answer this question, I will document my findings in this blog series. And if all goes well, I’ll create a video on how to do this on your own.\nThe process is looking fairly easy, but I reckon we’ll bump into problems along the way. What we need to do is: Create some vector graphics and formula’s to use in the video. In my case, I will be making them in R, exporting to PDF and layering them in illustrator. Next up is to create a storyboard. Shoot a video, and finally edit it all together in after effects.\nThat’s the plan at least. I will be doing a remake of my earlier analysis of variance videos. And if all goes well, I’ll tackle the fundamentals of null hypotheses testing."
  },
  {
    "objectID": "content/post/GR_2019_blog_2/index.html",
    "href": "content/post/GR_2019_blog_2/index.html",
    "title": "Not 3D tracking yet",
    "section": "",
    "text": "So, it’s taken some time before I could really start this grassroot project, but I finally got the ball rolling. Looking at my own plan in my previous post I immediately went another rout. As I will base my first video on my earlier screencast on ANOVA (in Dutch), I decided to download the auto generated transcript from my YouTube channel. This gave me a rough outline with timestamps and all.\nReading through the transcript, it became clear this was much too long. So, I wrote a shortened script that is much more to the point.\nNext up, was creating the graph I want to show in the video. Writing some R code, quickly landed me the plot I wanted. In the next step I followed the instruction that Peter Farago laid out in the video below (left), and fired up illustrator to import my PDF. There, adding layers was easy. But getting the right path into the correct layer was a bit of a puzzle. Turning paths on and off, showed me which vector element was what. Making it easier to identify where everyting needed to go.\n\n\n\n\n\n\nI made a lot of mistakes along the way, but I will spare you that pain. In the final Illustrator step, a quick CMD-A selected everything. Turning all the line colors white, made sure I could see the plot in After Effects.\nPeter’s instructions were still very helpful as I initially forgot to convert the vector layers to shapes. Now that this is all covered, I could create a trim path to animate the individual lines. I’m now creating the animation as we speak. You can watch the preview above (right).\nOne of the problems with animating is the timing. How long should each part be visible. For that, it might be easier if I first record the script and tune the animation accordingly. I will follow up on this progress in the next post."
  },
  {
    "objectID": "content/post/GR_2019_blog_3/index.html",
    "href": "content/post/GR_2019_blog_3/index.html",
    "title": "Timing is everything",
    "section": "",
    "text": "As mentioned in my previous grassroots blog, creating the animation I wanted for my 3D tracking video wasn’t that hard. This time I decided to follow my own advice and write the script first. After recording the audio in one session and trimming all the mistakes, I finally had an outline for the timing of the animation.\nBy importing the audio track into after effects, I was able to place the animation in such a way that it aligned perfectly. So I now have a synced animation that you can view in the clip below.\n\n\n\n\nNow the next puzzle will be the video recording. By first recording only the audio, I essentially ruined the possibility of doing a talking-head video. So, I plan to shoot some videos of only my hands explaining the animation without showing my head. And maybe try to do a lip-sync recording for a few parts.\nIf you missed the previous posts on my grassroots project, you can find them here."
  },
  {
    "objectID": "content/post/GR_2019_blog_4/index.html",
    "href": "content/post/GR_2019_blog_4/index.html",
    "title": "3D tracked!",
    "section": "",
    "text": "Do you remember that grassroots project I started back in 2019? Well, after months of COVID crisis management and online teaching, I finally came around to finishing the project during the winter break.\n\n\nThough I’m moderately pleased with the result, my conclusion is that it’s way too much work to be worth the effort. Though I enjoyed messing around with adobe after effects, much time could have been saved by leaving this part to the experts.\nAs mentioned in my previous blog, It’s all about the timing. I came to appreciate this aspect of teaching even more during this project. Making an animation happen at the touch of a button, precisely at the right time, makes for a more natural teaching experience.\nAs I have been live lecturing online the last few months, I found this timing aspect can easily be done using interactive webGL widgets. As shown in the clip below, It takes so much less effort to get the timing right.\n\n\nImagine using these 3D models and overlaying them in realtime on the table or even augmented in a lecture hall. I feel a next grassroots coming up. You can read the previous grassroods blogs here."
  }
]